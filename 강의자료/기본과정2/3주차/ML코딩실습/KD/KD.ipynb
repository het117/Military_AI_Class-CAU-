{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNrINqDOz4m+NsemoB8Najz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Distilling the Knowledge in a Neural Network\n","- 2022.09.29 minji kwak\n","-----------\n","- reference(paper): Distilling the Knowledge in a Neural Network (https://arxiv.org/abs/1503.02531)\n","- reference(github): https://github.com/shriramsb/Distilling-the-Knowledge-in-a-Neural-Network"],"metadata":{"id":"mHrg7cUOeylr"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4MSIisBPeqDc","executionInfo":{"status":"ok","timestamp":1664360941829,"user_tz":-540,"elapsed":2486,"user":{"displayName":"곽민지","userId":"14805877853838255722"}},"outputId":"651651ec-2571-4c95-cd31-959ac4d331a1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["### Import and Setting"],"metadata":{"id":"thyzt8qIgtJp"}},{"cell_type":"code","source":["cd /content/drive/MyDrive/ML_coding"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rGALVU-LhVEv","executionInfo":{"status":"ok","timestamp":1664360943846,"user_tz":-540,"elapsed":539,"user":{"displayName":"곽민지","userId":"14805877853838255722"}},"outputId":"e694b4c3-8bf3-405d-8b38-4019f3ba2c2e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ML_coding\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import math\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","import pickle\n","import argparse\n","import time\n","import itertools\n","from copy import deepcopy\n","import os\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","import networks\n","import utils\n","    \n","%load_ext autoreload\n","%autoreload 2"],"metadata":{"id":"bLg2gpLFfSsj","executionInfo":{"status":"ok","timestamp":1664360945832,"user_tz":-540,"elapsed":936,"user":{"displayName":"곽민지","userId":"14805877853838255722"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["use_gpu = True    # set use_gpu to True if system has gpu   # id of gpu to be used\n","cpu_device = torch.device('cpu')\n","# fast_device is where computation (training, inference) happens\n","fast_device = torch.device('cpu')\n","if use_gpu:\n","    os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # set visible devices depending on system configuration\n","    fast_device = torch.device('cuda:0')"],"metadata":{"id":"1JzBkilnfXOu","executionInfo":{"status":"ok","timestamp":1664360947795,"user_tz":-540,"elapsed":357,"user":{"displayName":"곽민지","userId":"14805877853838255722"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def reproducibilitySeed():\n","    \"\"\"\n","    Ensure reproducibility of results; Seeds to 0\n","    \"\"\"\n","    torch_init_seed = 0\n","    torch.manual_seed(torch_init_seed)\n","    numpy_init_seed = 0\n","    np.random.seed(numpy_init_seed)\n","    if use_gpu:\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","\n","reproducibilitySeed()"],"metadata":{"id":"8gq2oRNafayX","executionInfo":{"status":"ok","timestamp":1664360949034,"user_tz":-540,"elapsed":3,"user":{"displayName":"곽민지","userId":"14805877853838255722"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["checkpoints_path = 'checkpoints_teacher/'\n","checkpoints_path_teacher = 'checkpoints_teacher/'\n","checkpoints_path_student = 'checkpoints_student/'\n","checkpoints_path_student_distill = 'checkpoints_student_distill/'\n","\n","\n","if not os.path.exists(checkpoints_path):\n","    os.mkdir(checkpoints_path)\n","if not os.path.exists(checkpoints_path_teacher):\n","    os.mkdir(checkpoints_path_teacher)\n","if not os.path.exists(checkpoints_path_student):\n","    os.mkdir(checkpoints_path_student)\n","if not os.path.exists(checkpoints_path_student_distill):\n","    os.mkdir(checkpoints_path_student_distill)"],"metadata":{"id":"2rn0uXIyfeLI","executionInfo":{"status":"ok","timestamp":1664362764937,"user_tz":-540,"elapsed":2,"user":{"displayName":"곽민지","userId":"14805877853838255722"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["Load dataset"],"metadata":{"id":"gsfXINxLfnXn"}},{"cell_type":"code","source":["import torchvision\n","import torchvision.transforms as transforms\n","\n","mnist_image_shape = (28, 28)\n","random_pad_size = 2\n","# Training images augmented by randomly shifting images by at max. 2 pixels in any of 4 directions\n","transform_train = transforms.Compose(\n","                [\n","                    transforms.RandomCrop(mnist_image_shape, random_pad_size),\n","                    transforms.ToTensor(),\n","                    transforms.Normalize([0.5], [0.5])\n","                ]\n","            )\n","\n","transform_test = transforms.Compose(\n","                [\n","                    transforms.ToTensor(),\n","                    transforms.Normalize([0.5], [0.5])\n","                ]\n","            )\n","\n","train_val_dataset = torchvision.datasets.MNIST(root='./MNIST_dataset/', train=True, \n","                                            download=True, transform=transform_train)\n","\n","test_dataset = torchvision.datasets.MNIST(root='./MNIST_dataset/', train=False, \n","                                            download=True, transform=transform_test)\n","\n","num_train = int(1.0 * len(train_val_dataset) * 95 / 100)\n","num_val = len(train_val_dataset) - num_train\n","train_dataset, val_dataset = torch.utils.data.random_split(train_val_dataset, [num_train, num_val])\n","\n","batch_size = 128\n","train_val_loader = torch.utils.data.DataLoader(train_val_dataset, batch_size=128, shuffle=True, num_workers=0)\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=0)\n","val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=0)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=0)"],"metadata":{"id":"2SOWn5Rwfceo","executionInfo":{"status":"ok","timestamp":1664361915202,"user_tz":-540,"elapsed":368,"user":{"displayName":"곽민지","userId":"14805877853838255722"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["### Teacher network"],"metadata":{"id":"737aGVr1fQHt"}},{"cell_type":"markdown","source":["Train teacher network"],"metadata":{"id":"rs1DM1QhfpCK"}},{"cell_type":"code","source":["num_epochs = 20\n","print_every = 100    # Interval size for which to print statistics of training"],"metadata":{"id":"pqaawFQYffiI","executionInfo":{"status":"ok","timestamp":1664361919016,"user_tz":-540,"elapsed":351,"user":{"displayName":"곽민지","userId":"14805877853838255722"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["- 10 epoch당 약 3분 소요"],"metadata":{"id":"pBBCvuAys6Ap"}},{"cell_type":"code","source":["# Hyperparamters can be tuned by setting required range below\n","# learning_rates = list(np.logspace(-4, -2, 3))\n","learning_rates = [1e-2]\n","learning_rate_decays = [0.95]    # learning rate decays at every epoch\n","# weight_decays = [0.0] + list(np.logspace(-5, -1, 5))\n","weight_decays = [1e-5]           # regularization weight\n","momentums = [0.9]\n","# dropout_probabilities = [(0.2, 0.5), (0.0, 0.0)]\n","dropout_probabilities = [(0.0, 0.0)]\n","hparams_list = []\n","for hparam_tuple in itertools.product(dropout_probabilities, weight_decays, learning_rate_decays, \n","                                        momentums, learning_rates):\n","    hparam = {}\n","    hparam['dropout_input'] = hparam_tuple[0][0]\n","    hparam['dropout_hidden'] = hparam_tuple[0][1]\n","    hparam['weight_decay'] = hparam_tuple[1]\n","    hparam['lr_decay'] = hparam_tuple[2]\n","    hparam['momentum'] = hparam_tuple[3]\n","    hparam['lr'] = hparam_tuple[4]\n","    hparams_list.append(hparam)\n","\n","results = {}\n","for hparam in hparams_list:\n","    print('Training with hparams' + utils.hparamToString(hparam))\n","    reproducibilitySeed()\n","    teacher_net = networks.TeacherNetwork()\n","    teacher_net = teacher_net.to(fast_device)\n","    hparam_tuple = utils.hparamDictToTuple(hparam)\n","    results[hparam_tuple] = utils.trainTeacherOnHparam(teacher_net, hparam, num_epochs, \n","                                                        train_val_loader, None, \n","                                                        print_every=print_every, \n","                                                        fast_device=fast_device)\n","    save_path = checkpoints_path + utils.hparamToString(hparam) + '_final.tar'\n","    torch.save({'results' : results[hparam_tuple], \n","                'model_state_dict' : teacher_net.state_dict(), \n","                'epoch' : num_epochs}, save_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a8nLRcHtfgvo","executionInfo":{"status":"ok","timestamp":1664362231785,"user_tz":-540,"elapsed":311736,"user":{"displayName":"곽민지","userId":"14805877853838255722"}},"outputId":"a1869612-d5bc-44f5-8ac9-cdaa5a0f89b2"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Training with hparamsdropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n","[1,   100/  469] train loss: 1.026 train accuracy: 0.609\n","[1,   200/  469] train loss: 0.693 train accuracy: 0.789\n","[1,   300/  469] train loss: 0.607 train accuracy: 0.812\n","[1,   400/  469] train loss: 0.525 train accuracy: 0.836\n","[2,   100/  469] train loss: 0.339 train accuracy: 0.883\n","[2,   200/  469] train loss: 0.300 train accuracy: 0.930\n","[2,   300/  469] train loss: 0.260 train accuracy: 0.922\n","[2,   400/  469] train loss: 0.248 train accuracy: 0.945\n","[3,   100/  469] train loss: 0.276 train accuracy: 0.938\n","[3,   200/  469] train loss: 0.183 train accuracy: 0.961\n","[3,   300/  469] train loss: 0.124 train accuracy: 0.961\n","[3,   400/  469] train loss: 0.168 train accuracy: 0.953\n","[4,   100/  469] train loss: 0.182 train accuracy: 0.945\n","[4,   200/  469] train loss: 0.195 train accuracy: 0.953\n","[4,   300/  469] train loss: 0.170 train accuracy: 0.953\n","[4,   400/  469] train loss: 0.187 train accuracy: 0.953\n","[5,   100/  469] train loss: 0.180 train accuracy: 0.938\n","[5,   200/  469] train loss: 0.230 train accuracy: 0.930\n","[5,   300/  469] train loss: 0.121 train accuracy: 0.953\n","[5,   400/  469] train loss: 0.072 train accuracy: 0.977\n","[6,   100/  469] train loss: 0.085 train accuracy: 0.977\n","[6,   200/  469] train loss: 0.183 train accuracy: 0.953\n","[6,   300/  469] train loss: 0.113 train accuracy: 0.969\n","[6,   400/  469] train loss: 0.070 train accuracy: 0.961\n","[7,   100/  469] train loss: 0.156 train accuracy: 0.969\n","[7,   200/  469] train loss: 0.057 train accuracy: 0.977\n","[7,   300/  469] train loss: 0.049 train accuracy: 0.992\n","[7,   400/  469] train loss: 0.082 train accuracy: 0.977\n","[8,   100/  469] train loss: 0.072 train accuracy: 0.961\n","[8,   200/  469] train loss: 0.184 train accuracy: 0.930\n","[8,   300/  469] train loss: 0.103 train accuracy: 0.961\n","[8,   400/  469] train loss: 0.174 train accuracy: 0.938\n","[9,   100/  469] train loss: 0.119 train accuracy: 0.969\n","[9,   200/  469] train loss: 0.047 train accuracy: 0.992\n","[9,   300/  469] train loss: 0.050 train accuracy: 0.977\n","[9,   400/  469] train loss: 0.055 train accuracy: 0.984\n","[10,   100/  469] train loss: 0.201 train accuracy: 0.938\n","[10,   200/  469] train loss: 0.107 train accuracy: 0.961\n","[10,   300/  469] train loss: 0.076 train accuracy: 0.977\n","[10,   400/  469] train loss: 0.087 train accuracy: 0.961\n","[11,   100/  469] train loss: 0.160 train accuracy: 0.961\n","[11,   200/  469] train loss: 0.070 train accuracy: 0.984\n","[11,   300/  469] train loss: 0.187 train accuracy: 0.953\n","[11,   400/  469] train loss: 0.026 train accuracy: 1.000\n","[12,   100/  469] train loss: 0.051 train accuracy: 0.984\n","[12,   200/  469] train loss: 0.067 train accuracy: 0.992\n","[12,   300/  469] train loss: 0.106 train accuracy: 0.984\n","[12,   400/  469] train loss: 0.111 train accuracy: 0.969\n","[13,   100/  469] train loss: 0.102 train accuracy: 0.977\n","[13,   200/  469] train loss: 0.026 train accuracy: 0.992\n","[13,   300/  469] train loss: 0.100 train accuracy: 0.961\n","[13,   400/  469] train loss: 0.064 train accuracy: 0.984\n","[14,   100/  469] train loss: 0.191 train accuracy: 0.930\n","[14,   200/  469] train loss: 0.092 train accuracy: 0.977\n","[14,   300/  469] train loss: 0.048 train accuracy: 0.977\n","[14,   400/  469] train loss: 0.241 train accuracy: 0.977\n","[15,   100/  469] train loss: 0.053 train accuracy: 0.977\n","[15,   200/  469] train loss: 0.052 train accuracy: 0.977\n","[15,   300/  469] train loss: 0.167 train accuracy: 0.969\n","[15,   400/  469] train loss: 0.087 train accuracy: 0.977\n","[16,   100/  469] train loss: 0.158 train accuracy: 0.969\n","[16,   200/  469] train loss: 0.032 train accuracy: 1.000\n","[16,   300/  469] train loss: 0.039 train accuracy: 0.992\n","[16,   400/  469] train loss: 0.160 train accuracy: 0.969\n","[17,   100/  469] train loss: 0.074 train accuracy: 0.992\n","[17,   200/  469] train loss: 0.031 train accuracy: 0.992\n","[17,   300/  469] train loss: 0.103 train accuracy: 0.953\n","[17,   400/  469] train loss: 0.033 train accuracy: 0.992\n","[18,   100/  469] train loss: 0.029 train accuracy: 0.992\n","[18,   200/  469] train loss: 0.094 train accuracy: 0.969\n","[18,   300/  469] train loss: 0.040 train accuracy: 0.992\n","[18,   400/  469] train loss: 0.101 train accuracy: 0.953\n","[19,   100/  469] train loss: 0.061 train accuracy: 0.977\n","[19,   200/  469] train loss: 0.188 train accuracy: 0.961\n","[19,   300/  469] train loss: 0.045 train accuracy: 0.992\n","[19,   400/  469] train loss: 0.038 train accuracy: 0.992\n","[20,   100/  469] train loss: 0.028 train accuracy: 1.000\n","[20,   200/  469] train loss: 0.036 train accuracy: 0.984\n","[20,   300/  469] train loss: 0.108 train accuracy: 0.953\n","[20,   400/  469] train loss: 0.037 train accuracy: 0.984\n"]}]},{"cell_type":"code","source":["# Calculate test accuracy\n","_, test_accuracy = utils.getLossAccuracyOnDataset(teacher_net, test_loader, fast_device)\n","print('test accuracy: ', test_accuracy)"],"metadata":{"id":"gCGWf71VfioY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664362270086,"user_tz":-540,"elapsed":1936,"user":{"displayName":"곽민지","userId":"14805877853838255722"}},"outputId":"9c106b0f-fd2d-4099-886d-08da7d852015"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["test accuracy:  0.9853\n"]}]},{"cell_type":"markdown","source":["### Student network"],"metadata":{"id":"QWc2zttBfMQ4"}},{"cell_type":"markdown","source":["Load teacher network"],"metadata":{"id":"zEMI70Q0gKSn"}},{"cell_type":"code","source":["checkpoints_path_teacher = 'checkpoints_teacher/'\n","checkpoints_path_student = 'checkpoints_student/'\n","checkpoints_path_student_distill = 'checkpoints_student_distill/'"],"metadata":{"id":"vNPQVGMxju5l","executionInfo":{"status":"ok","timestamp":1664362334143,"user_tz":-540,"elapsed":414,"user":{"displayName":"곽민지","userId":"14805877853838255722"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# set the hparams used for training teacher to load the teacher network\n","learning_rates = [1e-2]\n","learning_rate_decays = [0.95]\n","weight_decays = [1e-5]\n","momentums = [0.9]\n","# keeping dropout input = dropout hidden\n","dropout_probabilities = [(0.0, 0.0)]\n","hparams_list = []\n","for hparam_tuple in itertools.product(dropout_probabilities, weight_decays, learning_rate_decays, \n","                                        momentums, learning_rates):\n","    hparam = {}\n","    hparam['dropout_input'] = hparam_tuple[0][0]\n","    hparam['dropout_hidden'] = hparam_tuple[0][1]\n","    hparam['weight_decay'] = hparam_tuple[1]\n","    hparam['lr_decay'] = hparam_tuple[2]\n","    hparam['momentum'] = hparam_tuple[3]\n","    hparam['lr'] = hparam_tuple[4]\n","    hparams_list.append(hparam)\n","\n","\n","load_path = checkpoints_path_teacher + utils.hparamToString(hparams_list[0]) + '_final.tar'\n","teacher_net = networks.TeacherNetwork()\n","teacher_net.load_state_dict(torch.load(load_path, map_location=fast_device)['model_state_dict'])\n","teacher_net = teacher_net.to(fast_device)"],"metadata":{"id":"qINMqV5rfPDk","executionInfo":{"status":"ok","timestamp":1664362351341,"user_tz":-540,"elapsed":1537,"user":{"displayName":"곽민지","userId":"14805877853838255722"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["#  Calculate teacher test accuracy\n","_, test_accuracy = utils.getLossAccuracyOnDataset(teacher_net, test_loader, fast_device)\n","print('teacher test accuracy: ', test_accuracy)"],"metadata":{"id":"Ymb8U67OgNQT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664362358721,"user_tz":-540,"elapsed":2002,"user":{"displayName":"곽민지","userId":"14805877853838255722"}},"outputId":"6ceda746-5956-4fb7-b6ba-75292e1b4d75"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["teacher test accuracy:  0.9853\n"]}]},{"cell_type":"markdown","source":["Train studnet network without distillation"],"metadata":{"id":"3jy2s39CgRL1"}},{"cell_type":"code","source":["num_epochs = 20\n","print_every = 100"],"metadata":{"id":"Z3bBrCTsgOvC","executionInfo":{"status":"ok","timestamp":1664362361892,"user_tz":-540,"elapsed":440,"user":{"displayName":"곽민지","userId":"14805877853838255722"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["temperatures = [1]    # temperature for distillation loss\n","# trade-off between soft-target (st) cross-entropy and true-target (tt) cross-entropy;\n","# loss = alpha * st + (1 - alpha) * tt\n","alphas = [0.0]\n","learning_rates = [1e-2]\n","learning_rate_decays = [0.95]\n","weight_decays = [1e-5]\n","momentums = [0.9]\n","# No dropout used\n","dropout_probabilities = [(0.0, 0.0)]\n","hparams_list = []\n","for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, \n","                                        momentums, learning_rates):\n","    hparam = {}\n","    hparam['alpha'] = hparam_tuple[0]\n","    hparam['T'] = hparam_tuple[1]\n","    hparam['dropout_input'] = hparam_tuple[2][0]\n","    hparam['dropout_hidden'] = hparam_tuple[2][1]\n","    hparam['weight_decay'] = hparam_tuple[3]\n","    hparam['lr_decay'] = hparam_tuple[4]\n","    hparam['momentum'] = hparam_tuple[5]\n","    hparam['lr'] = hparam_tuple[6]\n","    hparams_list.append(hparam)\n","\n","results_no_distill = {}\n","for hparam in hparams_list:\n","    print('Training with hparams' + utils.hparamToString(hparam))\n","    reproducibilitySeed()\n","    student_net = networks.StudentNetwork()\n","    student_net = student_net.to(fast_device)\n","    hparam_tuple = utils.hparamDictToTuple(hparam)\n","    results_no_distill[hparam_tuple] = utils.trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs, \n","                                                                    train_val_loader, None, \n","                                                                    print_every=print_every, \n","                                                                    fast_device=fast_device)\n","    save_path = checkpoints_path_student + utils.hparamToString(hparam) + '_final.tar'\n","    torch.save({'results' : results_no_distill[hparam_tuple], \n","                'model_state_dict' : student_net.state_dict(), \n","                'epoch' : num_epochs}, save_path)"],"metadata":{"id":"TWfF9_dFgUxN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664363087778,"user_tz":-540,"elapsed":293653,"user":{"displayName":"곽민지","userId":"14805877853838255722"}},"outputId":"f45867fa-1ed9-4cfe-cbeb-19db8a924c66"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Training with hparamsT=1, alpha=0.0, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["[1,   100/  469] train loss: 0.914 train accuracy: 0.742\n","[1,   200/  469] train loss: 0.991 train accuracy: 0.664\n","[1,   300/  469] train loss: 0.675 train accuracy: 0.812\n","[1,   400/  469] train loss: 0.460 train accuracy: 0.867\n","[2,   100/  469] train loss: 0.376 train accuracy: 0.906\n","[2,   200/  469] train loss: 0.443 train accuracy: 0.859\n","[2,   300/  469] train loss: 0.277 train accuracy: 0.922\n","[2,   400/  469] train loss: 0.319 train accuracy: 0.898\n","[3,   100/  469] train loss: 0.254 train accuracy: 0.945\n","[3,   200/  469] train loss: 0.211 train accuracy: 0.938\n","[3,   300/  469] train loss: 0.239 train accuracy: 0.961\n","[3,   400/  469] train loss: 0.146 train accuracy: 0.953\n","[4,   100/  469] train loss: 0.281 train accuracy: 0.906\n","[4,   200/  469] train loss: 0.269 train accuracy: 0.930\n","[4,   300/  469] train loss: 0.171 train accuracy: 0.953\n","[4,   400/  469] train loss: 0.132 train accuracy: 0.961\n","[5,   100/  469] train loss: 0.135 train accuracy: 0.961\n","[5,   200/  469] train loss: 0.171 train accuracy: 0.945\n","[5,   300/  469] train loss: 0.191 train accuracy: 0.938\n","[5,   400/  469] train loss: 0.158 train accuracy: 0.953\n","[6,   100/  469] train loss: 0.097 train accuracy: 0.977\n","[6,   200/  469] train loss: 0.133 train accuracy: 0.961\n","[6,   300/  469] train loss: 0.105 train accuracy: 0.977\n","[6,   400/  469] train loss: 0.204 train accuracy: 0.969\n","[7,   100/  469] train loss: 0.057 train accuracy: 0.984\n","[7,   200/  469] train loss: 0.153 train accuracy: 0.969\n","[7,   300/  469] train loss: 0.167 train accuracy: 0.969\n","[7,   400/  469] train loss: 0.049 train accuracy: 0.992\n","[8,   100/  469] train loss: 0.099 train accuracy: 0.953\n","[8,   200/  469] train loss: 0.120 train accuracy: 0.961\n","[8,   300/  469] train loss: 0.132 train accuracy: 0.969\n","[8,   400/  469] train loss: 0.108 train accuracy: 0.961\n","[9,   100/  469] train loss: 0.093 train accuracy: 0.961\n","[9,   200/  469] train loss: 0.140 train accuracy: 0.953\n","[9,   300/  469] train loss: 0.133 train accuracy: 0.961\n","[9,   400/  469] train loss: 0.057 train accuracy: 0.992\n","[10,   100/  469] train loss: 0.095 train accuracy: 0.969\n","[10,   200/  469] train loss: 0.120 train accuracy: 0.961\n","[10,   300/  469] train loss: 0.158 train accuracy: 0.953\n","[10,   400/  469] train loss: 0.063 train accuracy: 0.984\n","[11,   100/  469] train loss: 0.089 train accuracy: 0.969\n","[11,   200/  469] train loss: 0.121 train accuracy: 0.961\n","[11,   300/  469] train loss: 0.140 train accuracy: 0.961\n","[11,   400/  469] train loss: 0.096 train accuracy: 0.961\n","[12,   100/  469] train loss: 0.132 train accuracy: 0.930\n","[12,   200/  469] train loss: 0.152 train accuracy: 0.953\n","[12,   300/  469] train loss: 0.062 train accuracy: 0.984\n","[12,   400/  469] train loss: 0.093 train accuracy: 0.969\n","[13,   100/  469] train loss: 0.142 train accuracy: 0.945\n","[13,   200/  469] train loss: 0.183 train accuracy: 0.945\n","[13,   300/  469] train loss: 0.159 train accuracy: 0.969\n","[13,   400/  469] train loss: 0.198 train accuracy: 0.945\n","[14,   100/  469] train loss: 0.083 train accuracy: 0.969\n","[14,   200/  469] train loss: 0.043 train accuracy: 1.000\n","[14,   300/  469] train loss: 0.083 train accuracy: 0.961\n","[14,   400/  469] train loss: 0.135 train accuracy: 0.961\n","[15,   100/  469] train loss: 0.033 train accuracy: 1.000\n","[15,   200/  469] train loss: 0.018 train accuracy: 1.000\n","[15,   300/  469] train loss: 0.069 train accuracy: 0.984\n","[15,   400/  469] train loss: 0.076 train accuracy: 0.977\n","[16,   100/  469] train loss: 0.102 train accuracy: 0.977\n","[16,   200/  469] train loss: 0.078 train accuracy: 0.977\n","[16,   300/  469] train loss: 0.096 train accuracy: 0.977\n","[16,   400/  469] train loss: 0.070 train accuracy: 0.984\n","[17,   100/  469] train loss: 0.128 train accuracy: 0.969\n","[17,   200/  469] train loss: 0.091 train accuracy: 0.977\n","[17,   300/  469] train loss: 0.113 train accuracy: 0.961\n","[17,   400/  469] train loss: 0.078 train accuracy: 0.977\n","[18,   100/  469] train loss: 0.078 train accuracy: 0.977\n","[18,   200/  469] train loss: 0.195 train accuracy: 0.945\n","[18,   300/  469] train loss: 0.073 train accuracy: 0.977\n","[18,   400/  469] train loss: 0.107 train accuracy: 0.953\n","[19,   100/  469] train loss: 0.063 train accuracy: 0.977\n","[19,   200/  469] train loss: 0.055 train accuracy: 0.977\n","[19,   300/  469] train loss: 0.031 train accuracy: 0.992\n","[19,   400/  469] train loss: 0.050 train accuracy: 0.984\n","[20,   100/  469] train loss: 0.028 train accuracy: 1.000\n","[20,   200/  469] train loss: 0.080 train accuracy: 0.961\n","[20,   300/  469] train loss: 0.062 train accuracy: 0.992\n","[20,   400/  469] train loss: 0.098 train accuracy: 0.969\n"]}]},{"cell_type":"code","source":["# Calculate student test accuracy\n","_, test_accuracy = utils.getLossAccuracyOnDataset(student_net, test_loader, fast_device)\n","print('student test accuracy (w/o distillation): ', test_accuracy)"],"metadata":{"id":"07NUApK-gXWo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664363118922,"user_tz":-540,"elapsed":2025,"user":{"displayName":"곽민지","userId":"14805877853838255722"}},"outputId":"16a68e24-4e31-4921-c89d-c1f14e57635c"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["student test accuracy (w/o distillation):  0.9819\n"]}]},{"cell_type":"markdown","source":["Train studnet network using distillation"],"metadata":{"id":"Mi56mK8tgc3l"}},{"cell_type":"code","source":["num_epochs = 20\n","print_every = 100"],"metadata":{"id":"rFKuu7XIgew1","executionInfo":{"status":"ok","timestamp":1664363597394,"user_tz":-540,"elapsed":330,"user":{"displayName":"곽민지","userId":"14805877853838255722"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["temperatures = [10]\n","# trade-off between soft-target (st) cross-entropy and true-target (tt) cross-entropy;\n","# loss = alpha * st + (1 - alpha) * tt\n","alphas = [0.5]\n","learning_rates = [1e-2]\n","learning_rate_decays = [0.95]\n","weight_decays = [1e-5]\n","momentums = [0.9]\n","dropout_probabilities = [(0.0, 0.0)]\n","hparams_list = []\n","for hparam_tuple in itertools.product(alphas, temperatures, dropout_probabilities, weight_decays, learning_rate_decays, \n","                                        momentums, learning_rates):\n","    hparam = {}\n","    hparam['alpha'] = hparam_tuple[0]\n","    hparam['T'] = hparam_tuple[1]\n","    hparam['dropout_input'] = hparam_tuple[2][0]\n","    hparam['dropout_hidden'] = hparam_tuple[2][1]\n","    hparam['weight_decay'] = hparam_tuple[3]\n","    hparam['lr_decay'] = hparam_tuple[4]\n","    hparam['momentum'] = hparam_tuple[5]\n","    hparam['lr'] = hparam_tuple[6]\n","    hparams_list.append(hparam)\n","\n","results_distill = {}\n","for hparam in hparams_list:\n","    print('Training with hparams' + utils.hparamToString(hparam))\n","    reproducibilitySeed()\n","    student_net = networks.StudentNetwork()\n","    student_net = student_net.to(fast_device)\n","    hparam_tuple = utils.hparamDictToTuple(hparam)\n","    results_distill[hparam_tuple] = utils.trainStudentOnHparam(teacher_net, student_net, hparam, num_epochs, \n","                                                                train_val_loader, None, \n","                                                                print_every=print_every, \n","                                                                fast_device=fast_device)\n","    save_path = checkpoints_path_student_distill + utils.hparamToString(hparam) + '_final.tar'\n","    torch.save({'results' : results_distill[hparam_tuple], \n","                'model_state_dict' : student_net.state_dict(), \n","                'epoch' : num_epochs}, save_path)"],"metadata":{"id":"sHNP1cDsggIk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664364207283,"user_tz":-540,"elapsed":292858,"user":{"displayName":"곽민지","userId":"14805877853838255722"}},"outputId":"f4d3e17f-61f4-4ed3-9545-1fb9aa6035a3"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Training with hparamsT=10, alpha=0.5, dropout_hidden=0.0, dropout_input=0.0, lr=0.01, lr_decay=0.95, momentum=0.9, weight_decay=1e-05\n","[1,   100/  469] train loss: 4.133 train accuracy: 0.734\n","[1,   200/  469] train loss: 2.181 train accuracy: 0.836\n","[1,   300/  469] train loss: 1.236 train accuracy: 0.875\n","[1,   400/  469] train loss: 0.798 train accuracy: 0.945\n","[2,   100/  469] train loss: 0.543 train accuracy: 0.969\n","[2,   200/  469] train loss: 0.454 train accuracy: 0.930\n","[2,   300/  469] train loss: 0.439 train accuracy: 0.961\n","[2,   400/  469] train loss: 0.367 train accuracy: 0.969\n","[3,   100/  469] train loss: 0.332 train accuracy: 0.961\n","[3,   200/  469] train loss: 0.245 train accuracy: 0.977\n","[3,   300/  469] train loss: 0.267 train accuracy: 0.969\n","[3,   400/  469] train loss: 0.193 train accuracy: 0.984\n","[4,   100/  469] train loss: 0.295 train accuracy: 0.953\n","[4,   200/  469] train loss: 0.267 train accuracy: 0.953\n","[4,   300/  469] train loss: 0.225 train accuracy: 0.969\n","[4,   400/  469] train loss: 0.180 train accuracy: 1.000\n","[5,   100/  469] train loss: 0.153 train accuracy: 0.977\n","[5,   200/  469] train loss: 0.216 train accuracy: 0.961\n","[5,   300/  469] train loss: 0.193 train accuracy: 0.961\n","[5,   400/  469] train loss: 0.201 train accuracy: 0.953\n","[6,   100/  469] train loss: 0.182 train accuracy: 0.984\n","[6,   200/  469] train loss: 0.171 train accuracy: 0.984\n","[6,   300/  469] train loss: 0.134 train accuracy: 0.984\n","[6,   400/  469] train loss: 0.213 train accuracy: 0.953\n","[7,   100/  469] train loss: 0.132 train accuracy: 0.977\n","[7,   200/  469] train loss: 0.167 train accuracy: 0.977\n","[7,   300/  469] train loss: 0.209 train accuracy: 0.961\n","[7,   400/  469] train loss: 0.133 train accuracy: 0.977\n","[8,   100/  469] train loss: 0.129 train accuracy: 0.984\n","[8,   200/  469] train loss: 0.171 train accuracy: 0.961\n","[8,   300/  469] train loss: 0.144 train accuracy: 0.961\n","[8,   400/  469] train loss: 0.137 train accuracy: 0.969\n","[9,   100/  469] train loss: 0.136 train accuracy: 0.969\n","[9,   200/  469] train loss: 0.152 train accuracy: 0.977\n","[9,   300/  469] train loss: 0.123 train accuracy: 0.984\n","[9,   400/  469] train loss: 0.118 train accuracy: 0.992\n","[10,   100/  469] train loss: 0.126 train accuracy: 0.992\n","[10,   200/  469] train loss: 0.141 train accuracy: 0.961\n","[10,   300/  469] train loss: 0.165 train accuracy: 0.961\n","[10,   400/  469] train loss: 0.113 train accuracy: 1.000\n","[11,   100/  469] train loss: 0.116 train accuracy: 0.977\n","[11,   200/  469] train loss: 0.139 train accuracy: 0.969\n","[11,   300/  469] train loss: 0.148 train accuracy: 0.984\n","[11,   400/  469] train loss: 0.119 train accuracy: 0.977\n","[12,   100/  469] train loss: 0.140 train accuracy: 0.969\n","[12,   200/  469] train loss: 0.113 train accuracy: 0.977\n","[12,   300/  469] train loss: 0.118 train accuracy: 0.977\n","[12,   400/  469] train loss: 0.120 train accuracy: 0.977\n","[13,   100/  469] train loss: 0.122 train accuracy: 0.977\n","[13,   200/  469] train loss: 0.133 train accuracy: 0.984\n","[13,   300/  469] train loss: 0.166 train accuracy: 0.969\n","[13,   400/  469] train loss: 0.153 train accuracy: 0.961\n","[14,   100/  469] train loss: 0.129 train accuracy: 0.961\n","[14,   200/  469] train loss: 0.094 train accuracy: 0.992\n","[14,   300/  469] train loss: 0.116 train accuracy: 0.984\n","[14,   400/  469] train loss: 0.122 train accuracy: 0.969\n","[15,   100/  469] train loss: 0.090 train accuracy: 1.000\n","[15,   200/  469] train loss: 0.090 train accuracy: 1.000\n","[15,   300/  469] train loss: 0.099 train accuracy: 0.984\n","[15,   400/  469] train loss: 0.109 train accuracy: 0.984\n","[16,   100/  469] train loss: 0.123 train accuracy: 0.977\n","[16,   200/  469] train loss: 0.121 train accuracy: 0.969\n","[16,   300/  469] train loss: 0.104 train accuracy: 0.977\n","[16,   400/  469] train loss: 0.117 train accuracy: 0.984\n","[17,   100/  469] train loss: 0.107 train accuracy: 0.984\n","[17,   200/  469] train loss: 0.108 train accuracy: 0.984\n","[17,   300/  469] train loss: 0.120 train accuracy: 0.969\n","[17,   400/  469] train loss: 0.098 train accuracy: 0.977\n","[18,   100/  469] train loss: 0.111 train accuracy: 0.984\n","[18,   200/  469] train loss: 0.129 train accuracy: 0.969\n","[18,   300/  469] train loss: 0.084 train accuracy: 0.984\n","[18,   400/  469] train loss: 0.130 train accuracy: 0.984\n","[19,   100/  469] train loss: 0.096 train accuracy: 0.992\n","[19,   200/  469] train loss: 0.089 train accuracy: 0.984\n","[19,   300/  469] train loss: 0.106 train accuracy: 0.977\n","[19,   400/  469] train loss: 0.094 train accuracy: 0.992\n","[20,   100/  469] train loss: 0.084 train accuracy: 1.000\n","[20,   200/  469] train loss: 0.096 train accuracy: 0.969\n","[20,   300/  469] train loss: 0.082 train accuracy: 0.984\n","[20,   400/  469] train loss: 0.106 train accuracy: 0.969\n"]}]},{"cell_type":"code","source":["# Calculate student test accuracy\n","_, test_accuracy = utils.getLossAccuracyOnDataset(student_net, test_loader, fast_device)\n","print('student test accuracy (w distillation): ', test_accuracy)"],"metadata":{"id":"6b7yFa4tgkEI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664364658898,"user_tz":-540,"elapsed":2119,"user":{"displayName":"곽민지","userId":"14805877853838255722"}},"outputId":"0ac4aa99-062d-413c-8100-996a659e4eb7"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["student test accuracy (w distillation):  0.982\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Jwysb7oJ3TWM"},"execution_count":null,"outputs":[]}]}